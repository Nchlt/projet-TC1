{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.metrics import log_loss, accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(61878,)\n",
      "(61878, 93)\n",
      "(144368, 93)\n",
      "Construction des centroïdes\n",
      "Construction de la représentation dcDistance\n",
      "Construction terminée \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/train.csv\").drop(\"id\",axis=1)\n",
    "df_test = pd.read_csv(\"../data/test.csv\").drop(\"id\",axis=1)\n",
    "\n",
    "labels = df[\"target\"].values\n",
    "print(type(labels))\n",
    "print(labels.shape)\n",
    "\n",
    "unique_labels = np.unique(labels)\n",
    "nb_labels = len(unique_labels)\n",
    "\n",
    "df_train = df.drop(\"target\", axis=1)\n",
    "\n",
    "X = df_train.values\n",
    "X_test = df_test.values\n",
    "\n",
    "print(X.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "y = []\n",
    "for label in labels:\n",
    "    y.append(int(label[-1:])-1)\n",
    "y = np.asarray(y)\n",
    "\n",
    "\n",
    "print(\"Construction des centroïdes\")\n",
    "centroids = []\n",
    "for label in unique_labels:\n",
    "    same_labels = df_train.loc[df['target'] == label]\n",
    "    same_labels = same_labels.values\n",
    "    centroids.append(same_labels.sum(axis = 0)/same_labels.shape[0])\n",
    "centroids = np.asarray(centroids)\n",
    "\n",
    "\n",
    "print(\"Construction de la représentation dcDistance\")\n",
    "\n",
    "X_dc = pairwise_distances(X,centroids)\n",
    "X_test_dc = pairwise_distances(X_test, centroids, metric='minkowski')\n",
    "\n",
    "print(\"Construction terminée \\n\")\n",
    "\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_norm = Normalizer().fit_transform(X_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_norm = Normalizer().fit_transform(X_dc)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.2,\n",
    "random_state=42)\n",
    "\n",
    "target_names = ['class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7', 'class_8', 'class_9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit terminé\n",
      "0.65\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class_1       0.57      0.23      0.33       399\n",
      "    class_2       0.66      0.85      0.74      3178\n",
      "    class_3       0.51      0.36      0.42      1561\n",
      "    class_4       0.62      0.14      0.22       538\n",
      "    class_5       0.96      0.95      0.96       565\n",
      "    class_6       0.90      0.91      0.91      2884\n",
      "    class_7       0.62      0.62      0.62       552\n",
      "    class_8       0.82      0.87      0.84      1674\n",
      "    class_9       0.79      0.82      0.80      1025\n",
      "\n",
      "avg / total       0.74      0.75      0.73     12376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_tmp = ExtraTreesClassifier(n_estimators=250, random_state=0, n_jobs=-1)\n",
    "clf = CalibratedClassifierCV(clf_tmp, method='isotonic', cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Fit terminé\")\n",
    "pred = clf.predict_proba(X_test)\n",
    "pred_for_acc = clf.predict(X_test)\n",
    "print(\"%.2f\" % log_loss(y_test, pred, eps=1e-15, normalize=True))\n",
    "print(classification_report(y_test, pred_for_acc, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.1 s, sys: 836 ms, total: 51.9 s\n",
      "Wall time: 52.1 s\n",
      "Accuracy : 0.66\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class_1       0.00      0.00      0.00       399\n",
      "    class_2       0.53      0.96      0.68      3178\n",
      "    class_3       0.00      0.00      0.00      1561\n",
      "    class_4       0.00      0.00      0.00       538\n",
      "    class_5       0.93      0.92      0.92       565\n",
      "    class_6       0.88      0.85      0.87      2884\n",
      "    class_7       0.87      0.20      0.32       552\n",
      "    class_8       0.62      0.79      0.69      1674\n",
      "    class_9       0.69      0.69      0.69      1025\n",
      "\n",
      "avg / total       0.56      0.66      0.58     12376\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nour/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Knn nature \n",
    "#clf = KNeighborsClassifier(n_neighbors=200, n_jobs=3)\n",
    "clf = SVC(kernel='linear', C=0.4)\n",
    "%time clf.fit(X_train, y_train)\n",
    "#%time pred = clf.predict_proba(X_test)\n",
    "pred_for_acc = clf.predict(X_test)\n",
    "#print(\"Kaggle log loss metric : %.2f\" % log_loss(y_test, pred, eps=1e-15, normalize=True))\n",
    "print(\"Accuracy : %.2f\" % accuracy_score(y_test, pred_for_acc))\n",
    "print(classification_report(y_test, pred_for_acc, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Knn calibré\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "X_train_nb = Normalizer().fit_transform(X_train)\n",
    "X_test_nb = Normalizer().fit_transform(X_test)\n",
    "%time clf.fit(X_train_nb, y_train)\n",
    "%time pred = clf.predict_proba(X_test_nb)\n",
    "pred_for_acc = clf.predict(X_test)\n",
    "print(\"Kaggle log loss metric : %.2f\" % log_loss(y_test, pred, eps=1e-15, normalize=True))\n",
    "print(\"Accuracy : %.2f\" % accuracy_score(y_test, pred_for_acc))\n",
    "print(classification_report(y_test, pred_for_acc, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.8 s, sys: 313 ms, total: 20.1 s\n",
      "Wall time: 7.17 s\n",
      "CPU times: user 24.3 s, sys: 200 ms, total: 24.5 s\n",
      "Wall time: 8.48 s\n",
      "Kaggle log loss metric : 0.75\n",
      "Accuracy : 0.71\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class_1       0.31      0.08      0.12       399\n",
      "    class_2       0.62      0.86      0.72      3178\n",
      "    class_3       0.47      0.28      0.35      1561\n",
      "    class_4       0.62      0.03      0.06       538\n",
      "    class_5       0.90      0.95      0.92       565\n",
      "    class_6       0.88      0.87      0.87      2884\n",
      "    class_7       0.60      0.51      0.55       552\n",
      "    class_8       0.75      0.83      0.79      1674\n",
      "    class_9       0.71      0.78      0.74      1025\n",
      "\n",
      "avg / total       0.69      0.71      0.67     12376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#clf_tmp_1 = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "#clf_tmp_2 = CalibratedClassifierCV(clf_tmp_1, method='isotonic', cv=5)\n",
    "#clf = AdaBoostClassifier(clf_tmp_1,\n",
    "#    n_estimators=10,\n",
    "#    learning_rate=1.0)\n",
    "\n",
    "clf_tmp = KNeighborsClassifier(n_neighbors=300, n_jobs=-1)\n",
    "clf = CalibratedClassifierCV(clf_tmp, method='isotonic', cv=5)\n",
    "%time clf.fit(X_train, y_train)\n",
    "%time pred = clf.predict_proba(X_test)\n",
    "pred_for_acc = clf.predict(X_test)\n",
    "print(\"Kaggle log loss metric : %.2f\" % log_loss(y_test, pred, eps=1e-15, normalize=True))\n",
    "print(\"Accuracy : %.2f\" % accuracy_score(y_test, pred_for_acc))\n",
    "print(classification_report(y_test, pred_for_acc, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump((clf, pred), open('../data/knn300.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "%time clf.fit(X_train, y_train)\n",
    "%time pred = clf.predict_proba(X_test)\n",
    "pred_for_acc = clf.predict(X_test)\n",
    "print(\"Kaggle log loss metric : %.2f\" % log_loss(y_test, pred, eps=1e-15, normalize=True))\n",
    "print(\"Accuracy : %.2f\" % accuracy_score(y_test, pred_for_acc))\n",
    "print(classification_report(y_test, pred_for_acc, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "clf = CalibratedClassifierCV(f, method='isotonic', cv=5)\n",
    "%time clf.fit(X_train, y_train)\n",
    "%time pred = clf.predict_proba(X_test)\n",
    "pred_for_acc = clf.predict(X_test)\n",
    "print(\"Kaggle log loss metric : %.2f\" % log_loss(y_test, pred, eps=1e-15, normalize=True))\n",
    "print(\"Accuracy : %.2f\" % accuracy_score(y_test, pred_for_acc))\n",
    "print(classification_report(y_test, pred_for_acc, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_tmp = ExtraTreesClassifier(n_estimators=250, random_state=0, n_jobs=-1)\n",
    "clf = CalibratedClassifierCV(clf_tmp, method='isotonic', cv=5)\n",
    "%time clf.fit(X_train, y_train)\n",
    "%time pred = clf.predict_proba(X_test)\n",
    "pred_for_acc = clf.predict(X_test)\n",
    "print(\"Kaggle log loss metric : %.2f\" % log_loss(y_test, pred, eps=1e-15, normalize=True))\n",
    "print(\"Accuracy : %.2f\" % accuracy_score(y_test, pred_for_acc))\n",
    "print(classification_report(y_test, pred_for_acc, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A supprimer\n",
    "clf = ExtraTreesClassifier(n_estimators=150, min_samples_split=2, random_state=0, n_jobs=-1)\n",
    "%time clf.fit(X_train, y_train)\n",
    "%time pred = clf.predict_proba(X_test)\n",
    "pred_for_acc = clf.predict(X_test)\n",
    "print(\"Kaggle log loss metric : %.2f\" % log_loss(y_test, pred, eps=1e-15, normalize=True))\n",
    "print(\"Accuracy : %.2f\" % accuracy_score(y_test, pred_for_acc))\n",
    "print(classification_report(y_test, pred_for_acc, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodes longues (feature reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(X_dc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "#k_bests = np.arange(5, 90, step=5)\n",
    "k_bests=[2]\n",
    "#clf = MultinomialNB()\n",
    "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "\n",
    "for k_best in k_bests:\n",
    "    selection = SelectKBest(chi2, k=k_best)\n",
    "    X_new = selection.fit_transform(X, y)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2,\n",
    "                                                        random_state=42)\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict_proba(X_test)\n",
    "    print('--- k_best = '+str(k_best))\n",
    "    print(\"%.2f\" % log_loss(y_test, pred, eps=1e-15, normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf', C=1.0 , cache_size=4000, decision_function_shape='ovo')\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict_proba(X_test)\n",
    "pred_for_acc = clf.predict(X_test)\n",
    "print(\"%.2f\" % log_loss(y_test, pred, eps=1e-15, normalize=True))\n",
    "print(\"Accuracy : %.2f\" % accuracy_score(y_test, pred_for_acc))\n",
    "print(classification_report(y_test, pred_for_acc, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
